from __future__ import annotations

# ============================== 1) IMPORTS & CONFIG ==============================
import os
import re
import time
from datetime import datetime
from typing import List, Tuple, Optional

import pandas as pd

# -------- Selenium --------
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

# -------- Google Drive API (Service Account) --------
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload, MediaIoBaseUpload
from io import BytesIO

# ------------------------------- Runtime Config --------------------------------
URL: str = "https://nationalthaiwater.onwr.go.th/waterlevel"
CSV_OUT: str = r"C:\Project_End\CodeProject\waterlevel_report.csv"

# ----- Google Drive -----
ENABLE_GOOGLE_DRIVE_UPLOAD: bool = True
SERVICE_ACCOUNT_FILE: str = r"C:\Project_End\CodeProject\githubproject-467507-653192ee67bf.json"
DRIVE_FOLDER_ID: str = "1YV69Vah7gNvXbYZNKwjQyxQXT36MWjRH"
CSV_MIMETYPE: str = "text/csv"
DRIVE_FILE_ID: Optional[str] = "1zfUZeqp5qJrKxtgHu6XmqrN9omvaxVuP"

PAGE_TIMEOUT: int = 40
CLICK_TIMEOUT: int = 15
SLEEP_BETWEEN_PAGES: float = 1.0

# ================= Email Notify (SMTP) =================
EMAIL_ENABLED: bool = os.getenv("EMAIL_ENABLED", "true").lower() == "true"
SMTP_SERVER: str = os.getenv("SMTP_SERVER", "smtp.gmail.com")
SMTP_PORT: int   = int(os.getenv("SMTP_PORT", "587"))
EMAIL_SENDER: str = os.getenv("EMAIL_SENDER", "pph656512@gmail.com")
EMAIL_PASSWORD: str = os.getenv("EMAIL_PASSWORD", "nfns uuan ayrx uykm")
EMAIL_TO: str      = os.getenv("EMAIL_TO", "pph656512@gmail.com")

def send_email(subject: str, body_text: str) -> None:
    if not EMAIL_ENABLED:
        return
    try:
        from email.mime.text import MIMEText
        from email.mime.multipart import MIMEMultipart
        import smtplib

        msg = MIMEMultipart()
        msg["From"] = EMAIL_SENDER
        msg["To"] = EMAIL_TO
        msg["Subject"] = subject
        msg.attach(MIMEText(body_text, "plain", "utf-8"))

        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
        server.starttls()
        server.login(EMAIL_SENDER, EMAIL_PASSWORD)
        server.sendmail(EMAIL_SENDER, [x.strip() for x in EMAIL_TO.split(",")], msg.as_string())
        server.quit()
        print("üìß ‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÅ‡∏•‡πâ‡∏ß")
    except Exception as e:
        print("‚ö†Ô∏è ‡∏™‡πà‡∏á‡∏≠‡∏µ‡πÄ‡∏°‡∏•‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß:", e)

# =========================== 2) Google Drive helpers ===========================
def _check_prereq() -> None:
    if not ENABLE_GOOGLE_DRIVE_UPLOAD:
        return
    if not SERVICE_ACCOUNT_FILE or not os.path.exists(SERVICE_ACCOUNT_FILE):
        raise FileNotFoundError(f"‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå Service Account: {SERVICE_ACCOUNT_FILE}")
    if not DRIVE_FOLDER_ID:
        raise ValueError("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á DRIVE_FOLDER_ID")
    if not DRIVE_FILE_ID_OVERRIDE:
        raise ValueError("‡∏ï‡πâ‡∏≠‡∏á‡∏ï‡∏±‡πâ‡∏á DRIVE_FILE_ID (DRIVE_FILE_ID_OVERRIDE) ‡πÄ‡∏õ‡πá‡∏ô fileId ‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡∏õ‡∏•‡∏≤‡∏¢‡∏ó‡∏≤‡∏á")

def build_drive_service():
    scopes = ["https://www.googleapis.com/auth/drive"]
    creds = service_account.Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=scopes)
    return build("drive", "v3", credentials=creds, cache_discovery=False)

def drive_read_csv_as_df(service, file_id: str) -> Optional[pd.DataFrame]:
    """‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î CSV ‡∏à‡∏≤‡∏Å Drive ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô DataFrame (‡∏ñ‡πâ‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á ‡∏Ñ‡∏∑‡∏ô DataFrame ‡∏ß‡πà‡∏≤‡∏á)"""
    try:
        req = service.files().get_media(fileId=file_id)
        fh = BytesIO()
        downloader = MediaIoBaseDownload(fh, req)
        done = False
        while not done:
            _, done = downloader.next_chunk()
        fh.seek(0)
        data = fh.read()
        if not data:
            return pd.DataFrame()
        try:
            text = data.decode("utf-8-sig")
        except UnicodeDecodeError:
            text = data.decode("utf-8", errors="replace")
        if not text.strip():
            return pd.DataFrame()
        return pd.read_csv(pd.io.common.StringIO(text))
    except HttpError as e:
        print(f"‚ö†Ô∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏≤‡∏Å Drive ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        return None
    except Exception as e:
        print(f"‚ö†Ô∏è ‡∏≠‡πà‡∏≤‡∏ô CSV ‡πÄ‡∏õ‡πá‡∏ô DataFrame ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {e}")
        return None

def drive_merge_and_update_df_update_only(
    df_new: pd.DataFrame,
    key_cols: tuple[str, ...],
    local_out_path: Optional[str] = None,
) -> tuple[str, str, int]:
    """
    ‡∏£‡∏ß‡∏° df_new ‡∏Å‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏° (DRIVE_FILE_ID_OVERRIDE) ‡πÅ‡∏•‡πâ‡∏ß 'update' ‡∏Å‡∏•‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    - ‡πÑ‡∏°‡πà‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤/‡πÑ‡∏°‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà ‡∏ñ‡πâ‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ñ‡∏∂‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ -> raise
    """
    _check_prereq()
    service = build_drive_service()

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå/‡∏°‡∏µ‡∏≠‡∏¢‡∏π‡πà‡∏à‡∏£‡∏¥‡∏á‡∏Ç‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°
    try:
        service.files().get(fileId=DRIVE_FILE_ID_OVERRIDE, fields="id,name").execute()
    except HttpError as e:
        raise RuntimeError(
            f"Service Account ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏™‡∏¥‡∏ó‡∏ò‡∏¥‡πå‡∏´‡∏£‡∏∑‡∏≠‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡πÑ‡∏°‡πà‡∏û‡∏ö (fileId={DRIVE_FILE_ID_OVERRIDE})"
        ) from e

    # ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡∏°‡∏≤‡∏£‡∏ß‡∏°
    df_old = drive_read_csv_as_df(service, DRIVE_FILE_ID_OVERRIDE)
    if df_old is None or df_old.empty:
        df_merged = df_new.copy()
    else:
        common = [c for c in df_new.columns if c in df_old.columns]
        df_merged = pd.concat([df_old[common], df_new[common] if common else df_new], ignore_index=True)

    # ‡∏•‡∏ö‡∏ã‡πâ‡∏≥‡∏ï‡∏≤‡∏° key
    effective_keys = [c for c in key_cols if c in df_merged.columns]
    df_merged = df_merged.drop_duplicates(subset=effective_keys, keep="last") if effective_keys \
                else df_merged.drop_duplicates(keep="last")

    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÇ‡∏•‡∏Ñ‡∏≠‡∏• (optional)
    if local_out_path:
        os.makedirs(os.path.dirname(local_out_path), exist_ok=True)
        df_merged.to_csv(local_out_path, index=False, encoding="utf-8-sig")

    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏° (‡∏ï‡πâ‡∏≠‡∏á‡∏™‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô bytes)
    buf = BytesIO()
    csv_bytes = df_merged.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")
    buf.write(csv_bytes); buf.seek(0)
    media = MediaIoBaseUpload(buf, mimetype=CSV_MIMETYPE, resumable=True)

    updated = service.files().update(
        fileId=DRIVE_FILE_ID_OVERRIDE,
        media_body=media,
        supportsAllDrives=True,
    ).execute()

    return "update", updated["id"], len(df_merged)

# ============================= 3) Selenium scraper =============================
def make_driver() -> webdriver.Chrome:
    opt = Options()
    opt.add_argument("--headless=new")
    opt.add_argument("--no-sandbox")
    opt.add_argument("--disable-dev-shm-usage")
    opt.add_argument(
        "user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36"
    )
    drv = webdriver.Chrome(options=opt)
    drv.set_page_load_timeout(60)
    return drv

def scrape_waterlevel() -> tuple[list[list[str]], float]:
    driver = make_driver()
    start_time = time.time()
    try:
        driver.get(URL)
        rows = WebDriverWait(driver, PAGE_TIMEOUT).until(
            EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".MuiTable-root tbody tr"))
        )
        all_data: list[list[str]] = []
        current_date = datetime.now().strftime("%m/%d/%y")
        while True:
            for row in rows:
                cols = [c.text.strip() for c in row.find_elements(By.CSS_SELECTOR, "td")]
                if len(cols) < 5:
                    continue
                # ‡πÄ‡∏ï‡∏¥‡∏°‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡πâ‡∏≤‡∏¢‡∏ï‡∏≤‡∏£‡∏≤‡∏á
                if len(cols) == 9:
                    cols[-1] = current_date
                else:
                    cols.append(current_date)
                all_data.append(cols)
            try:
                next_btn = WebDriverWait(driver, CLICK_TIMEOUT).until(
                    EC.element_to_be_clickable((By.XPATH, "//span[@title='Next Page']/button"))
                )
                if not next_btn.is_enabled():
                    break
                first_row_old = rows[0]
                driver.execute_script("arguments[0].click();", next_btn)
                WebDriverWait(driver, PAGE_TIMEOUT).until(EC.staleness_of(first_row_old))
                rows = WebDriverWait(driver, PAGE_TIMEOUT).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, ".MuiTable-root tbody tr"))
                )
                if SLEEP_BETWEEN_PAGES > 0:
                    time.sleep(SLEEP_BETWEEN_PAGES)
                print("‚û°Ô∏è Next Page Loaded")
            except Exception:
                break
        return all_data, start_time
    finally:
        driver.quit()

# ============================= 4) Text/Parsing helpers =============================
def extract_thai(text: str) -> str:
    if pd.isna(text) or text is None:
        return ""
    m = re.search(r"[‡∏Å-‡πô].*", str(text))
    return m.group(0).strip() if m else ""

# =============================== 5) Save & Upload ===============================
def save_and_upload(all_data: list[list[str]]) -> tuple[int, Optional[str], Optional[str]]:
    if not all_data:
        print("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å")
        return 0, None, None

    # ‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏ó‡πà‡∏≤‡∏Å‡∏±‡∏ô
    max_cols = max(len(r) for r in all_data)
    all_data = [r + [""] * (max_cols - len(r)) for r in all_data]

    # ‚úÖ ‡πÉ‡∏ä‡πâ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    headers = [
        "Station","Location","Time","Water_Level","Bank_Level",
        "Gauge_Zero","Capacity_Percent","Status","Data_Time",
    ]
    if len(headers) < max_cols:
        headers += [f"Extra_{i + 1}" for i in range(max_cols - len(headers))]

    df_new = pd.DataFrame(all_data, columns=headers)
    # ‡∏ñ‡πâ‡∏≤‡∏Ñ‡πà‡∏≤‡πÉ‡∏ô Station ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÉ‡∏´‡πâ‡∏î‡∏∂‡∏á‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡πÑ‡∏ó‡∏¢‡∏≠‡∏≠‡∏Å‡∏°‡∏≤ (‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏à‡∏∞‡∏Ñ‡∏á‡πÑ‡∏ß‡πâ‡∏Å‡πá‡πÑ‡∏î‡πâ)
    df_new["Station"] = df_new["Station"].apply(extract_thai)

    drive_action = None
    drive_file_id = None
    merged_rows = 0

    if ENABLE_GOOGLE_DRIVE_UPLOAD:
        try:
            # ‚úÖ ‡∏Ñ‡∏µ‡∏¢‡πå‡∏•‡∏ö‡∏ã‡πâ‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©
            key_cols = ("Station", "Time", "Data_Time")
            drive_action, drive_file_id, merged_rows = drive_merge_and_update_df_update_only(
                df_new=df_new,
                key_cols=key_cols,
                local_out_path=CSV_OUT,   # ‡πÄ‡∏Å‡πá‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏ß‡∏°‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÑ‡∏ß‡πâ‡πÇ‡∏•‡∏Ñ‡∏≠‡∏•‡∏î‡πâ‡∏ß‡∏¢
            )
            print(f"‚úÖ ‡∏£‡∏ß‡∏°+‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏î‡∏¥‡∏°‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: action={drive_action}, id={drive_file_id}, rows={merged_rows}")
            return merged_rows, drive_action, drive_file_id
        except Exception as e:
            print("‚ö†Ô∏è ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Å‡∏•‡∏±‡∏ö Drive ‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß:", e)
            df_new.to_csv(CSV_OUT, index=False, encoding="utf-8-sig")
            return len(df_new), None, None
    else:
        df_new.to_csv(CSV_OUT, index=False, encoding="utf-8-sig")
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å {len[df_new]} ‡πÅ‡∏ñ‡∏ß -> {os.path.abspath(CSV_OUT)}")
        return len(df_new), None, None

# ==================================== 6) Main ====================================
def main() -> None:
    all_data, t0 = scrape_waterlevel()
    rows_saved, drive_action, drive_file_id = save_and_upload(all_data)
    elapsed = time.time() - t0

    when = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    subject = f"[WaterLevel] Finish OK rows={rows_saved} @ {when}"
    body = (
        f"‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå ({when})\n"
        f"- ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å/‡∏£‡∏ß‡∏°‡πÅ‡∏•‡πâ‡∏ß: {rows_saved} ‡πÅ‡∏ñ‡∏ß\n"
        f"- ‡πÑ‡∏ü‡∏•‡πå CSV: {os.path.abspath(CSV_OUT)}\n"
        f"- ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤: {elapsed:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n"
    )
    if ENABLE_GOOGLE_DRIVE_UPLOAD:
        body += f"- Drive: {drive_action or '-'} (id={drive_file_id or '-'})\n"

    send_email(subject, body)
    print(f"‚è± ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {elapsed:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        when = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        subject = f"[WaterLevel] FAILED @ {when}"
        body = f"‡∏™‡∏Ñ‡∏£‡∏¥‡∏õ‡∏ï‡πå‡∏•‡πâ‡∏°‡πÄ‡∏´‡∏•‡∏ß‡πÄ‡∏°‡∏∑‡πà‡∏≠ {when}\n\nError:\n{repr(e)}"
        send_email(subject, body)
        raise
